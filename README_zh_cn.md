[English](README.md) | [ç®€ä½“ä¸­æ–‡](README_zh_cn.md)

<!-- ## **Hunyuan3D-1.0** -->

<p align="center">
  <img src="./assets/logo.png"  height=200>
</p>

# Tencent Hunyuan3D-1.0: A Unified Framework for Text-to-3D and Image-to-3D Generation

<div align="center">
  <a href="https://github.com/tencent/Hunyuan3D-1"><img src="https://img.shields.io/static/v1?label=Code&message=Github&color=blue&logo=github-pages"></a> &ensp;
  <a href="https://3d.hunyuan.tencent.com"><img src="https://img.shields.io/static/v1?label=Homepage&message=Tencent%20Hunyuan3D&color=blue&logo=github-pages"></a> &ensp;
  <a href="https://arxiv.org/pdf/2411.02293"><img src="https://img.shields.io/static/v1?label=Tech Report&message=Arxiv&color=red&logo=arxiv"></a> &ensp;
  <a href="https://huggingface.co/Tencent/Hunyuan3D-1"><img src="https://img.shields.io/static/v1?label=Checkpoints&message=HuggingFace&color=yellow"></a> &ensp;
  <a href="https://huggingface.co/spaces/Tencent/Hunyuan3D-1"><img src="https://img.shields.io/static/v1?label=Demo&message=HuggingFace&color=yellow"></a> &ensp;
</div>


## ğŸ”¥ğŸ”¥ğŸ”¥ æ›´æ–°!!

* Nov 21, 2024: ğŸ’¬ æˆ‘ä»¬ä¸Šä¼ äº†æ–°çš„çº¹ç†çƒ˜ç„™æ¨¡å—ï¼
* Nov 20, 2024: ğŸ’¬ æˆ‘ä»¬æ·»åŠ äº†ä¸­æ–‡ç‰ˆçš„ READMEã€‚
* Nov 18, 2024: ğŸ’¬ æ„Ÿè°¢ç¬¬ä¸‰æ–¹å¼€å‘è€…å®ç°ComfyUIï¼[[1]](https://github.com/jtydhr88/ComfyUI-Hunyuan3D-1-wrapper)[[2]](https://github.com/MrForExample/ComfyUI-3D-Pack)[[3]](https://github.com/TTPlanetPig/Comfyui_Hunyuan3D)
* Nov 5, 2024: ğŸ’¬ å·²ç»æ”¯æŒå›¾ç”Ÿ3Dã€‚è¯·åœ¨[script](#using-gradio)ä½“éªŒã€‚
* Nov 5, 2024: ğŸ’¬ å·²ç»æ”¯æŒæ–‡ç”Ÿ3Dï¼Œè¯·åœ¨[script](#using-gradio)ä½“éªŒã€‚


## ğŸ“‘ å¼€æºè®¡åˆ’

- [x] Inference 
- [x] Checkpoints
- [x] Baking
- [ ] ComfyUI
- [ ] Training
- [ ] Distillation Version
- [ ] TensorRT Version



## **æ¦‚è¦**
<p align="center">
  <img src="./assets/teaser.png"  height=450>
</p>

ä¸ºäº†è§£å†³ç°æœ‰çš„3Dç”Ÿæˆæ¨¡å‹åœ¨ç”Ÿæˆé€Ÿåº¦å’Œæ³›åŒ–èƒ½åŠ›ä¸Šå­˜åœ¨ä¸è¶³ï¼Œæˆ‘ä»¬å¼€æºäº†æ··å…ƒ3D-1.0æ¨¡å‹ï¼Œå¯ä»¥å¸®åŠ©3Dåˆ›ä½œè€…å’Œè‰ºæœ¯å®¶è‡ªåŠ¨åŒ–ç”Ÿäº§3Dèµ„äº§ã€‚æˆ‘ä»¬çš„æ¨¡å‹é‡‡ç”¨ä¸¤é˜¶æ®µç”Ÿæˆæ–¹æ³•ï¼Œåœ¨ä¿è¯è´¨é‡å’Œå¯æ§çš„åŸºç¡€ä¸Šï¼Œä»…éœ€10ç§’å³å¯ç”Ÿæˆ3Dèµ„äº§ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§å¤šè§†è§’æ‰©æ•£æ¨¡å‹ï¼Œè½»é‡ç‰ˆæ¨¡å‹èƒ½å¤Ÿåœ¨å¤§çº¦4ç§’å†…é«˜æ•ˆç”Ÿæˆå¤šè§†è§’å›¾åƒï¼Œè¿™äº›å¤šè§†è§’å›¾åƒä»ä¸åŒçš„è§†è§’æ•æ‰äº†3Dèµ„äº§çš„ä¸°å¯Œçš„çº¹ç†å’Œå‡ ä½•å…ˆéªŒï¼Œå°†ä»»åŠ¡ä»å•è§†è§’é‡å»ºæ¾å¼›åˆ°å¤šè§†è§’é‡å»ºã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å‰é¦ˆé‡å»ºæ¨¡å‹ï¼Œåˆ©ç”¨ä¸Šä¸€é˜¶æ®µç”Ÿæˆçš„å¤šè§†è§’å›¾åƒã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨å¤§çº¦3ç§’å†…å¿«é€Ÿè€Œå‡†ç¡®åœ°é‡å»º3Dèµ„äº§ã€‚é‡å»ºæ¨¡å‹å­¦ä¹ å¤„ç†å¤šè§†è§’æ‰©æ•£å¼•å…¥çš„å™ªå£°å’Œä¸ä¸€è‡´æ€§ï¼Œå¹¶åˆ©ç”¨æ¡ä»¶å›¾åƒä¸­çš„å¯ç”¨ä¿¡æ¯é«˜æ•ˆæ¢å¤3Dç»“æ„ã€‚æœ€ç»ˆï¼Œè¯¥æ¨¡å‹å¯ä»¥å®ç°è¾“å…¥ä»»æ„å•è§†è§’å®ç°ä¸‰ç»´ç”Ÿæˆã€‚


## ğŸ‰ **Hunyuan3D-1.0 æ¨¡å‹æ¶æ„**

<p align="center">
  <img src="./assets/overview_3.png"  height=400>
</p>


## ğŸ“ˆ æ¯”è¾ƒ

é€šè¿‡å’Œå…¶ä»–å¼€æºæ¨¡å‹æ¯”è¾ƒ, æ··å…ƒ3D-1.0åœ¨5é¡¹æŒ‡æ ‡éƒ½å¾—åˆ°äº†æœ€é«˜ç”¨æˆ·è¯„åˆ†ã€‚ç»†èŠ‚è¯·æŸ¥çœ‹ä»¥ä¸‹ç”¨æˆ·ç ”ç©¶ç»“æœã€‚

è½»é‡ç‰ˆæ¨¡å‹ä»…éœ€10så³å¯å®Œæˆå•å›¾ç”Ÿæˆ3Dï¼Œæ ‡å‡†ç‰ˆåˆ™å¤§çº¦éœ€è¦25sã€‚ä»¥ä¸‹æ•£ç‚¹å›¾è¡¨æ˜è…¾è®¯æ··å…ƒ3D-1.0å®ç°äº†è´¨é‡å’Œé€Ÿåº¦çš„åˆç†å¹³è¡¡ã€‚

<p align="center">
  <img src="./assets/radar.png"  height=300>
  <img src="./assets/runtime.png"  height=300>
</p>

## ä½¿ç”¨

#### å¤åˆ¶ä»£ç ä»“åº“

```shell
git clone https://github.com/tencent/Hunyuan3D-1
cd Hunyuan3D-1
```

#### Linuxç³»ç»Ÿå®‰è£…

env_install.sh è„šæœ¬æä¾›äº†å¦‚ä½•å®‰è£…ç¯å¢ƒï¼š

```
conda create -n hunyuan3d-1 python=3.9 or 3.10 or 3.11 or 3.12
conda activate hunyuan3d-1

pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu121
bash env_install.sh

# or
pip3 install -r requirements.txt --index-url https://download.pytorch.org/whl/cu121
pip3 install git+https://github.com/facebookresearch/pytorch3d@stable
pip3 install git+https://github.com/NVlabs/nvdiffrast
```

ç”±äºdust3rçš„è®¸å¯è¯é™åˆ¶, æˆ‘ä»¬ä»…æä¾›å…¶å®‰è£…é€”å¾„:

```
cd third_party
git clone --recursive https://github.com/naver/dust3r.git

cd ../third_party/weights
wget https://download.europe.naverlabs.com/ComputerVision/DUSt3R/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth

```


<details>
<summary>ğŸ’¡ä¸€äº›ç¯å¢ƒå®‰è£…å»ºè®®</summary>
    
å¯ä»¥é€‰æ‹©å®‰è£… xformers æˆ– flash_attn è¿›è¡ŒåŠ é€Ÿ:

```
pip install xformers --index-url https://download.pytorch.org/whl/cu121
```
```
pip install flash_attn
```

Most environment errors are caused by a mismatch between machine and packages. You can try manually specifying the version, as shown in the following successful cases:
```
# python3.9
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118 
```

when install pytorch3d, the gcc version is preferably greater than 9, and the gpu driver should not be too old.

</details>

#### ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹

æ¨¡å‹ä¸‹è½½é“¾æ¥ [https://huggingface.co/tencent/Hunyuan3D-1](https://huggingface.co/tencent/Hunyuan3D-1):

+ `Hunyuan3D-1/lite`, lite model for multi-view generation.
+ `Hunyuan3D-1/std`, standard model for multi-view generation.
+ `Hunyuan3D-1/svrm`, sparse-view reconstruction model.


ä¸ºäº†é€šè¿‡Hugging Faceä¸‹è½½æ¨¡å‹ï¼Œè¯·å…ˆä¸‹è½½ huggingface-cli. (å®‰è£…ç»†èŠ‚å¯è§ [here](https://huggingface.co/docs/huggingface_hub/guides/cli).)

```shell
python3 -m pip install "huggingface_hub[cli]"
```

è¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ä¸‹è½½æ¨¡å‹:

```shell
mkdir weights
huggingface-cli download tencent/Hunyuan3D-1 --local-dir ./weights

mkdir weights/hunyuanDiT
huggingface-cli download Tencent-Hunyuan/HunyuanDiT-v1.1-Diffusers-Distilled --local-dir ./weights/hunyuanDiT
```

#### æ¨ç† 
å¯¹äºæ–‡ç”Ÿ3Dï¼Œæˆ‘ä»¬æ”¯æŒä¸­/è‹±åŒè¯­ç”Ÿæˆï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿›è¡Œæœ¬åœ°æ¨ç†ï¼š
```python
python3 main.py \
    --text_prompt "a lovely rabbit" \
    --save_folder ./outputs/test/ \
    --max_faces_num 90000 \
    --do_texture_mapping \
    --do_render
```

å¯¹äºå›¾ç”Ÿ3Dï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿›è¡Œæœ¬åœ°æ¨ç†ï¼š
```python
python3 main.py \
    --image_prompt "/path/to/your/image" \
    --save_folder ./outputs/test/ \
    --max_faces_num 90000 \
    --do_texture_mapping \
    --do_render
```
æ›´å¤šå‚æ•°è¯¦è§£ï¼š

|    Argument        |  Default  |                     Description                     |
|:------------------:|:---------:|:---------------------------------------------------:|
|`--text_prompt`  |   None    |The text prompt for 3D generation         |
|`--image_prompt` |   None    |The image prompt for 3D generation         |
|`--t2i_seed`     |    0      |The random seed for generating images        |
|`--t2i_steps`    |    25     |The number of steps for sampling of text to image  |
|`--gen_seed`     |    0      |The random seed for generating 3d generation        |
|`--gen_steps`    |    50     |The number of steps for sampling of 3d generation  |
|`--max_faces_numm` | 90000  |The limit number of faces of 3d mesh |
|`--save_memory`   | False   |module will move to cpu automatically|
|`--do_texture_mapping` |   False    |Change vertex shadding to texture shading  |
|`--do_render`  |   False   |render gif   |


å¦‚æœæ˜¾å¡å†…å­˜æœ‰é™ï¼Œå¯ä»¥ä½¿ç”¨`--save_memory`å‘½ä»¤ï¼Œæœ€ä½æ˜¾å¡å†…å­˜è¦æ±‚å¦‚ä¸‹ï¼š
- Inference Std-pipeline requires 30GB VRAM (24G VRAM with --save_memory).
- Inference Lite-pipeline requires 22GB VRAM (18G VRAM with --save_memory).
- Note: --save_memory will increase inference time

```bash
bash scripts/text_to_3d_std.sh 
bash scripts/text_to_3d_lite.sh 
bash scripts/image_to_3d_std.sh 
bash scripts/image_to_3d_lite.sh 
```

å¦‚æœä½ çš„æ˜¾å¡å†…å­˜ä¸º16Gï¼Œå¯ä»¥åˆ†åˆ«åŠ è½½æ¨¡å‹åˆ°æ˜¾å¡:
```bash
bash scripts/text_to_3d_std_separately.sh 'a lovely rabbit' ./outputs/test # >= 16G
bash scripts/text_to_3d_lite_separately.sh 'a lovely rabbit' ./outputs/test # >= 14G
bash scripts/image_to_3d_std_separately.sh ./demos/example_000.png ./outputs/test  # >= 16G
bash scripts/image_to_3d_lite_separately.sh ./demos/example_000.png ./outputs/test # >= 10G
```

####  çº¹ç†çƒ˜ç„™

æˆ‘ä»¬æä¾›äº†çº¹ç†çƒ˜ç„™æ¨¡å—ã€‚å¯¹é½å’Œå˜å½¢è¿‡ç¨‹æ˜¯ä½¿ç”¨Dust3Rå®Œæˆçš„ï¼Œéµå®ˆCC BY-NC-SA 4.0è®¸å¯ã€‚è¯·æ³¨æ„ï¼Œè¿™æ˜¯ä¸€ä¸ªéå•†ä¸šè®¸å¯è¯ï¼Œå› æ­¤è¯¥æ¨¡å—ä¸èƒ½ç”¨äºå•†ä¸šç›®çš„ã€‚

```bash
mkdir -p ./third_party/weights/DUSt3R_ViTLarge_BaseDecoder_512_dpt
huggingface-cli download naver/DUSt3R_ViTLarge_BaseDecoder_512_dpt \
    --local-dir ./third_party/weights/DUSt3R_ViTLarge_BaseDecoder_512_dpt

cd ./third_party
git clone --recursive https://github.com/naver/dust3r.git

cd ..
```
å¦‚æœæ‚¨ä½¿ç”¨ç›¸å…³ä»£ç å’Œæƒé‡ï¼Œæˆ‘ä»¬ä¹Ÿåˆ—å‡ºä¸€äº›çƒ˜ç„™ç›¸å…³å‚æ•°ï¼š

|    Argument        |  Default  |                     Description                     |
|:------------------:|:---------:|:---------------------------------------------------:|
|`--do_bake`  |   False   | baking multi-view images onto mesh   |
|`--bake_align_times`  |   3   | alignment number of image and mesh |


æ³¨æ„ï¼šå¦‚æœéœ€è¦çƒ˜ç„™ï¼Œè¯·ç¡®ä¿`--do_bake`è®¾ç½®ä¸º`True`å¹¶ä¸”`--do_texture_mapping`ä¹Ÿè®¾ç½®ä¸º`True`ã€‚

```bash
python main.py ... --do_texture_mapping --do_bake (--do_render)

#### Gradioç•Œé¢éƒ¨ç½²

æˆ‘ä»¬åˆ†åˆ«æä¾›è½»é‡ç‰ˆå’Œæ ‡å‡†ç‰ˆç•Œé¢ï¼š

```shell
# std 
python3 app.py
python3 app.py --save_memory

# lite
python3 app.py --use_lite
python3 app.py --use_lite --save_memory
```

Gradioç•Œé¢ä½“éªŒåœ°å€ä¸º http://0.0.0.0:8080. è¿™é‡Œ 0.0.0.0 åº”å½“å¡«å†™è¿è¡Œæ¨¡å‹çš„æœºå™¨IPåœ°å€ã€‚

## ç›¸æœºå‚æ•°

ç”Ÿæˆå¤šè§†å›¾è§†è§’å›ºå®šä¸º

+ Azimuth (relative to input view): `+0, +60, +120, +180, +240, +300`.


## å¼•ç”¨

å¦‚æœæˆ‘ä»¬çš„ä»“åº“å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„å·¥ä½œ
```bibtex
@misc{yang2024tencent,
    title={Tencent Hunyuan3D-1.0: A Unified Framework for Text-to-3D and Image-to-3D Generation},
    author={Xianghui Yang and Huiwen Shi and Bowen Zhang and Fan Yang and Jiacheng Wang and Hongxu Zhao and Xinhai Liu and Xinzhou Wang and Qingxiang Lin and Jiaao Yu and Lifu Wang and Zhuo Chen and Sicong Liu and Yuhong Liu and Yong Yang and Di Wang and Jie Jiang and Chunchao Guo},
    year={2024},
    eprint={2411.02293},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
```
